Tomas Mardjan11:35
Yeah, we can do certain mlflow 1.
Profile picture of Speaker 1.
Speaker 111:35
Tomas. OK, thank you.
Profile picture of Tomas Mardjan.
Tomas Mardjan11:35
Share my screen.
Visible.
Profile picture of Speaker 1.
Speaker 111:35
Yes.
Profile picture of Tomas Mardjan.
Tomas Mardjan11:35
Alright, so and mlflow recipes, so give a bit of context first. So this is part of M Lflow too, and previously it was called, I think M Lflow pipelines. So yeah, from documentation what's it's about the idea is it will enable data scientists to more easily and quickly develop models and also deploy to production. And I think it's obvious why that's interesting for us.
Some other pros are. Yeah. So there are some basic templates on there, which of course facilitates everything because it reduces boilerplate.
Also some interesting capabilities such as caching and also some facilitations for deployment, so that's a bit really short and briefly what M lflow recipes offered.
And then what did we do so far? So, first of all.
 
 
And mlflow recipes is all about recipes and steps, and actually it looks really similar or has similar feel, at least to the model factory. So that's also another interesting topic to see. Yeah, because of course, having something that's open source is more convenient than, yeah, maintaining it ourselves.
So what's a recipe consists of different steps where every step is customizable, so just regular Python codes.
And steps are for example, yeah and just so in loading the data splits train et cetera, et cetera, making predictions et cetera. And the idea is that these steps are done defined in YAML file.
So what we did is investigate the basic example for ourselves to get better understanding how it exactly works, and also we're running everything locally and so far it seems to be working. So maybe we can only quickly show you a bit how it looks like.
So where's the recipe animal? So this is a bit how the YAML file looks like, so we have. Here we see the steps and then we have the different steps defined in. Just split, transform train. And as mentioned those steps we can customize. So for example if you look at transform.
Yeah, you can see that we you can create create your own custom functions methods to transform data et cetera et cetera.
And then yeah, as mentioned, we do everything locally. So we have a local and lflow server here.
And this is already first look of the results of these different steps. So it actually out-of-the-box creates these.
So if you run steps, you can always look at each step a bit more in detail. So for example here the interest step we can look at the scheme of data.
Bits are already a couple of rows of data.
Etcetera, etcetera. And you can do that basically for every step. So for example splits you can see what it actually how many train, how many validation tests for transform step. We can see that also the actual model objects is stored.
So yeah, a lot of interesting stuff that comes out of box and we will investigate further in the afternoon and give you a bit more of details then. So now we run through and basic example that's already there and now we're going to look into more how easily this to customize the different steps and add additional features.
Yeah. To see how convenient it actually is. So for now it looks really promising. But of course, if you need to customize, it might be that you bump into limitations. So that's it for us. Thank you.
Profile picture of Speaker 1.
Speaker 111:40
Thank you, Tomas. Again, another very promising topic I think.
Next up.
Two left volunteers.
 